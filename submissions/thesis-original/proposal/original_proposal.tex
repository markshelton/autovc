\documentclass[../thesis/thesis.tex]{subfiles}
\begin{document}
\ifcsdef{mainfile}{}{%
  \renewcommand{\thetitle}{A Supervised Approach to Predicting the Acquisition of Startups in the Private Markets \linebreak\linebreak Original Research Proposal}%
  \maketitle%
  \begin{refsection}
}

\begin{namelist}{xxxxxxxxxxxx}
\item[{\bf Component:}]
    Research Proposal
\item[{\bf Supervisors:}]
    Professor Melinda Hodkiewicz, Dr Tim French
\item[{\bf Degree:}]
    BPhil(Hons) (24 point project)
\item[{\bf University:}]
    The University of Western Australia
\end{namelist}

\section*{Background}
%In this section you should give some background to your research area. What is the problem you are tackling, and why is it worthwhile solving? Who has already done some work in this area, and what have they achieved?

High-growth technology companies (startups) are turning away from the public markets. Amazon went public in 1997, just two years after its first round of institutional financing, at a market capitalisation of \$440M \cite{kawamoto1997}. Contrast that with Uber, which remains private six years on and recently raised \$3.5B at a \$59B pre-money valuation \cite{buhr2016}. Time to Initial Public Offering (IPO) for Venture Capital (VC)-backed startups has more than doubled over the past 20 years while VC-backed startups pursuing an IPO has plummeted \cite{nvca2016}.

One explanation for why startups are staying private for longer is the accelerating nature of global business. Startups, particularly those backed by VC firms, are expected to scale fast and require frequent rounds of fundraising coupled with centralized, quick decision making. Such flexibility is not afforded to public companies, due to strict reporting and compliance requirements \cite{wies2015}.

Why does this waiting game matter? Principally, because it shifts value creation to the private markets. To put things in perspective, Microsoftâ€™s market capitalisation grew 500-fold following its IPO \cite{mcnamara2011}, but for Facebook to do the same now its valuation would have to exceed the global equity market \cite{raice2012}. VC funding for late-stage startups is approaching all-time highs, possibly because more investors are entering the private markets to seek higher returns \cite{nvca2016}.

Merger and Acquisitions (M\&A) have far surpassed IPOs as the most common liquidity event for startup founders and investors. In 2015, five times as many US-based VC-backed startups were acquired compared to those that went public through an IPO \cite{nvca2016}. Accordingly, startup founders and investors may be interested in predicting which startups are likely to be acquired and by whom. However, M\&A prediction is a challenging task.

Previous work has relied on relatively small data sets \cite{wei2008} because publicly-available information on private companies is scarce. In addition, previous work has focused on the financial or managerial features of potential targets \cite{hongjiu2007} with little work on textual or social network features.

Xiang and colleagues \cite{xiang2012} addressed some of these challenges by mining CrunchBase profiles and TechCrunch news articles to predict the acquisition of private startups. Their corpus was larger than previous studies: 38,617 TechCrunch news articles from June 2005 - December 2011 mentioning 5,075 companies, and a total of 59,631 CrunchBase profiles collected in January 2012. Their approach achieved a True Positive rate of between 60-79.8\% and a False Positive rate of between 0-8.3\%.

There are limitations to Xiang and colleagues' study: the CrunchBase corpus they studied was sparse, only a few common binary classification techniques were tested, and their approach didn't consider IPOs or bankruptcies as potential outcomes. In addition, it is unclear how robust their classifiers are through time. The study could be extended by applying the topic modelling approach to other text corpora such as patent filings, or by attempting a social network link prediction model.

\section*{Aim}
%Now state explicitly the hypothesis you aim to test. Make references to the items listed in the Reference section that back up your arguments for why this is a reasonable hypothesis to test, for example the work of Knuth~\cite{knuth}. Explain what you expect will be accomplished by undertaking this particular project.  Moreover, is it likely to have any other applications?

We aim to produce a supervised learning model that will accurately predict the acquisition of startups in the private markets. We will build on the study by Xiang and colleagues (2012) \cite{xiang2012}, introducing new features and classification techniques. In the previous study, True Positive rate (TP), False Positive rate (FP) and Area under the ROC curve (AUC) were the main evaluation metrics used (collectively, known as ``accuracy").

\begin{description}
\item[Hypothesis 1 (H1)] Xiang and colleagues (2012) \cite{xiang2012} results can be replicated

\item[H2] Introducing new classification techniques improves accuracy

Xiang and colleagues' study tested three common binary classification techniques: Bayesian Networks (BN), Support Vector Machines (SVM), and Logistic Regression (LR). BN significantly outperformed SVM and LR. The authors suggested that this was because of the high correlation among their features and absence of a linear separator in the feature space. We will test a number of new classification techniques including Random Forests (RF), CART Decision Trees (CART), and Restricted Bolzmann Machines (RBM), to try to improve the accuracy of the model.

\item[H3] Introducing additional CrunchBase features improves accuracy

Xiang and colleagues' study used a total of 22 factual features from CrunchBase profiles. No feature selection process was documented. A recent similar study on AngelList (which has a sharing agreement with CrunchBase) used 85 features of which 11 were selected \cite{beckwith2016}. Of those 11 features, many were not included in Xiang and colleagues' model. It is plausible that broadening the feature space may result in an improved model.

\item[H4] Introducing additional labels improves accuracy

Xiang and colleagues' study labelled startups as either ``acquired" or ``not acquired". The ``not acquired" category thus includes startups that have bankrupted as well as highly successful startups that went public through an IPO. It is plausible that the breadth of this category would lead to misclassification. Introducing labels for ``public" and ``bankrupt" could improve the accuracy of the model.

\item[H5] Using more recent CrunchBase corpora improves accuracy

Xiang and colleagues' study used a CrunchBase corpus from January 2012. They found the corpus relatively sparse at the time. Since 2012, the CrunchBase corpus has significantly grown. The CrunchBase Venture Program and the AngelList - CrunchBase data sharing agreement have contributed to the corpus, in addition to natural growth over time. It is plausible that a more recent CrunchBase corpus will provide a better basis for a more accurate model.

\end{description}

This study will improve our understanding of the determinants of startup acquisition in the private markets. The system devised by this study also has the potential to de-risk venture capital and encourage greater investment in private startups.

\section*{Method}
%In this section you should outline how you intend to go about accomplishing the aims you have set in the previous section. Try to break your grand aims down into small, achievable tasks.

\begin{enumerate}
\item Replicate study by Xiang et al. (2012) \cite{xiang2012}

We have requested access to the CrunchBase and TechCrunch datasets used in the previous study (Note: These datasets are \href{http://www.cs.cmu.edu/~guangx/crunchbase.html}{currently available on the Carnegie Mellon University intranet}). If we are unable to  access these datasets we will use a CrunchBase database snapshot from December 2013.

\begin{itemize}
\item   Features:
\begin{itemize}
\item   Factual Features (CrunchBase)
\begin{itemize}
\item   Basic Features e.g. office location, company age
\item   Financial Features e.g. investment per funding round
\item   Managerial Features e.g. number of acquired companies by founders
\end{itemize}
\item   Topic Features (TechCrunch articles)
\end{itemize}
\item   Outcome: Acquired? (CrunchBase)
\item   Processing:
\begin{itemize}
\item   Topic model - Latent Dirichlet Allocation (LDA)
\item   Classification techniques
\begin{itemize}
\item   Bayesian Network (BN)
\item   Support Vector Machines (SVM)
\item   Logistic Regression (LR)
\end{itemize}
\end{itemize}
\end{itemize}
\item Test additional classification techniques
\begin{itemize}
\item   CART Decision Tree (CART) as in \cite{beckwith2016}
\item   Restricted Bolzmann Machine (RBM) as in \cite{beckwith2016}
\item   Random Forest (RF)
\item   And other classification techniques
\end{itemize}
\item Expand the factual features set
\begin{itemize}
\item   Founder education (CrunchBase, Dec-2013) as in \cite{beckwith2016}
\item   Founder employment (CrunchBase, Dec-2013) as in \cite{beckwith2016}
\item   Founding team (CrunchBase, Dec-2013) as in \cite{spiegel2013}
\item   And other factual features in the CrunchBase corpus
\end{itemize}
\item Incorporate other potential startup outcomes
\begin{itemize}
\item   Outcomes: Bankrupt, Acquired, Public
\item   Classification techniques: One vs. all (OVA), All vs. all (AVA)
\end{itemize}
\item Test classifier robustness over different datasets
\begin{itemize}
\item Original dataset from Xiang et al. (2012) \cite{xiang2012}
\item CrunchBase readily-available snapshot (December 2013)
\item CrunchBase recent crawl (September 2016)
\end{itemize}
\item Extend topic modelling and introduce network features (stretch goal)
\begin{itemize}
\item   Domain-Constricted LDA model (TechCrunch articles) as in \cite{yuan2016}
\item   Patent similarity (Google Patents) as in \cite{huang2015}
\item   Social network link prediction (CrunchBase) as in \cite{shi2014,yuxian2013}
\item   And other types of features as time permits
\end{itemize}
\end{enumerate}

\subsection*{Timeline}
%Try to estimate how long you will spend on each task, and draw up a timetable for each sub-task.

Please see below (Table~\ref{tab:original_proposal:timeline}) for a schematic of the proposed methodology.

\begin{table}[!h]
  \centering
    \begin{tabular}{l|l|l}
    \toprule
    \textbf{S:W} & \textbf{Date} & \textbf{Task} \\
    \midrule
    {2:03} & Fri 19 August & Draft proposal due \\
    {2:05} & 29 Aug - 02 Sep & Proposal defence to research group \\
    {2:07} & Fri 09 September & Data collected \\
    {2:09} & Fri 23 September & Replicated previous study \\
    {2:SB} & Fri 30 September & Draft literature review due \\
    {2:12} & Fri 28 October & Revised proposal due \\
    {2:12} & Fri 28 October & Literature review due \\
    {2:17} & Fri 02 December & Completed main experiments \\
    {1:08} & Fri 28 April & Draft dissertation due \\
    {1:10} & Fri 12 May & Seminar title and abstract due \\
    {1:13} & Mon 29 May & Final dissertation due \\
    {1:13} & Fri 02 June & Poster due \\
    {1:13} & 29 May - 02 June & Seminar \\
    {1:17} & Mon 26 June & Corrected dissertation due \\
    \bottomrule
    \end{tabular}%
  \caption{Proposed timeline}
  \label{tab:original_proposal:timeline}%
\end{table}%

\subsection*{Software and Hardware Requirements}
%Outline what your specific requirements will be with regard to software and hardware, but note that any special requests might need to be approved by your supervisor and the Head of Department.

This project will be developed primarily in Python using scikit-learn, a free open-source machine learning library \cite{scikitlearn}. MySQL may be used to prepare datasets for processing. The system will be hosted on a public compute cloud, likely Amazon Web Services. A free academic license for CrunchBase has been requested.

\ifcsdef{mainfile}{}{
    \printbibliography
    \end{refsection}
    %\bibliography{../references/original_proposal}
}

\end{document}
