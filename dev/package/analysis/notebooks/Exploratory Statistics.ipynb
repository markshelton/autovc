{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup path\n",
    "path = 'C:/Users/mark/Documents/GitHub/honours/dev/package/'\n",
    "import sys; sys.path.append(path)\n",
    "\n",
    "#standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from collections import OrderedDict\n",
    "\n",
    "#third party imports\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "#local imports\n",
    "import analysis.dataPreparer as dp\n",
    "import analysis.getStages as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20,6\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "def set_style():\n",
    "    plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "    matplotlib.rc(\"font\", family=\"Times New Roman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#constants\n",
    "input_path = path+\"analysis/input/master.db\"\n",
    "flatten_config = path+\"analysis/config/master_feature.sql\"\n",
    "raw_flat_file = path+\"analysis/output/temp/raw.csv\"\n",
    "clean_flat_file = path+\"analysis/output/temp/clean.csv\"\n",
    "output_path = path+\"analysis/output/temp/output.db\"\n",
    "#output_path = path+\"analysis/output/autoVC/8/test/2015-04-06/2017-04-03/label_clean.csv\"\n",
    "\n",
    "dp.flatten_file(input_path, flatten_config, raw_flat_file, \"feature\")\n",
    "dp.clean_file(raw_flat_file, clean_flat_file)\n",
    "dp.load_file(output_path, clean_flat_file, \"feature\")\n",
    "df = dp.export_dataframe(output_path, \"feature\")\n",
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reload data from memory\n",
    "df = df_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stage_features = dict(\n",
    "    Age = 'confidence_context_broader_company_age_number',\n",
    "    FundingRounds = 'confidence_validation_funding_rounds_number',\n",
    "    FundingRaised = 'confidence_validation_funding_raised_value_total_number',\n",
    "    SeriesA = 'confidence_validation_funding_round_codes_list_a',\n",
    "    SeriesB = 'confidence_validation_funding_round_codes_list_b',\n",
    "    SeriesC = 'confidence_validation_funding_round_codes_list_c',\n",
    "    SeriesD = 'confidence_validation_funding_round_codes_list_d',\n",
    "    SeriesE = 'confidence_validation_funding_round_codes_list_e',\n",
    "    SeriesF = 'confidence_validation_funding_round_codes_list_f',\n",
    "    SeriesG = 'confidence_validation_funding_round_codes_list_g',\n",
    "    SeriesH = 'confidence_validation_funding_round_codes_list_h',\n",
    "    Closed = \"keys_company_status_closed_bool\",\n",
    "    Acquired = \"keys_company_status_acquired_bool\",\n",
    "    IPO = \"keys_company_status_ipo_bool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stage_features = dict(\n",
    "    Age = 'outcome_age_number',\n",
    "    FundingRounds = 'outcome_funding_rounds_number',\n",
    "    FundingRaised = 'outcome_funding_raised_value_total_number',\n",
    "    SeriesA = 'outcome_funding_round_codes_list_a',\n",
    "    SeriesB = 'outcome_funding_round_codes_list_b',\n",
    "    SeriesC = 'outcome_funding_round_codes_list_c',\n",
    "    SeriesD = 'outcome_funding_round_codes_list_d',\n",
    "    SeriesE = 'outcome_funding_round_codes_list_e',\n",
    "    SeriesF = 'outcome_funding_round_codes_list_f',\n",
    "    SeriesG = 'outcome_funding_round_codes_list_g',\n",
    "    SeriesH = 'outcome_funding_round_codes_list_h',\n",
    "    Closed = \"outcome_closed_bool\",\n",
    "    Acquired = \"outcome_acquired_bool\",\n",
    "    IPO = \"outcome_ipo_bool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_stages(df, **features):\n",
    "    df2 = df.copy()\n",
    "    df2[\"keys_company_stage\"] = \"Other\"\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"Closed\"]] >= 1), \"Closed\", df2[\"keys_company_stage\"])\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"Acquired\"]] >= 1), \"Acquired\", df2[\"keys_company_stage\"])\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"IPO\"]] >= 1), \"IPO\", df2[\"keys_company_stage\"])\n",
    "    df2[\"keys_company_stage_series-d+\"] = df2[[features[\"SeriesD\"],features[\"SeriesE\"],features[\"SeriesF\"],features[\"SeriesG\"],features[\"SeriesH\"]]].sum(axis=1)\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[\"keys_company_stage_series-d+\"] >= 1), \"Series D+\", df2[\"keys_company_stage\"])\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"SeriesC\"]] >= 1), \"Series C\", df2[\"keys_company_stage\"])\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"SeriesB\"]] >= 1), \"Series B\", df2[\"keys_company_stage\"])\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"SeriesA\"]] >= 1), \"Series A\", df2[\"keys_company_stage\"])\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"FundingRaised\"]] >= 0), \"Seed\", df2[\"keys_company_stage\"])\n",
    "    age_new_cutoff = df2[features[\"Age\"]][df2[\"keys_company_stage\"] == \"Seed\"].quantile(0.75)\n",
    "    df2[\"keys_company_stage\"] = np.where((df2[\"keys_company_stage\"] == \"Other\") & (df2[features[\"Age\"]] <= age_new_cutoff), \"Pre-Seed\", df2[\"keys_company_stage\"])\n",
    "    group_stages = {\"Other\" : \"Excluded\", \"Closed\" : \"Excluded\", \"IPO\" : \"Excluded\", \"Acquired\" : \"Excluded\", \"Pre-Seed\" : \"Included\",\n",
    "        \"Seed\" : \"Included\", \"Series A\" : \"Included\", \"Series B\" : \"Included\", \"Series C\" : \"Included\", \"Series D+\" : \"Included\"}\n",
    "    df2[\"keys_company_stage_group\"] = df2[\"keys_company_stage\"].map(group_stages)\n",
    "    ordinal_stages = {\"Pre-Seed\" : 1, \"Seed\" : 2, \"Series A\" : 3, \"Series B\" : 4, \"Series C\" : 5, \"Series D+\" : 6,\"Other\" : np.nan, \"Closed\" : -1, \"IPO\" : 7, \"Acquired\" : 8}\n",
    "    df2[\"keys_company_stage_number\"] = df2[\"keys_company_stage\"].map(ordinal_stages)\n",
    "    return df2[[\"keys_company_stage_group\", \"keys_company_stage\",\"keys_company_stage_number\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import analysis.getStages as gs\n",
    "import importlib\n",
    "importlib.reload(gs)\n",
    "stages = create_stages(df, **stage_features)\n",
    "df = pd.concat([stages, df], axis=1)\n",
    "print(\"Stages done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3 Preliminary Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df[\"keys_company_stage\"].value_counts())\n",
    "print(df[\"keys_company_stage\"].value_counts(normalize=True))\n",
    "print(df[\"keys_company_stage\"].value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed Other, Closed, Acquired & IPO groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.loc[df['keys_company_stage_group'] != \"Excluded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df[\"keys_company_stage\"].value_counts())\n",
    "print(df[\"keys_company_stage\"].value_counts(normalize=True))\n",
    "print(df[\"keys_company_stage\"].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order_1 = [\"Pre-Seed\", \"Seed\", \"Series A\", \"Series B\", \"Series C\", \"Series D+\"]\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.set_xlim(xmax=30)\n",
    "sns.boxplot(\n",
    "    x=\"confidence_context_broader_company_age_number\", \n",
    "    y=\"keys_company_stage\",\n",
    "    order=order_1,data=df, fliersize=0, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed companies older than 15 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_old_cutoff = df[\"confidence_context_broader_company_age_number\"][df[\"keys_company_stage\"] == \"Series D+\"].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_old_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.loc[df['confidence_context_broader_company_age_number'] <= age_old_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df[\"keys_company_stage\"].value_counts())\n",
    "print(df[\"keys_company_stage\"].value_counts(normalize=True))\n",
    "print(df[\"keys_company_stage\"].value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.4 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 3. Final test dataset counts grouped by lifecycle stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drops = [col for col in list(df) if col.startswith((\"key\",\"from\",\"outcome\",\"index\"))]\n",
    "X = df.drop(drops, axis=1)\n",
    "X = X.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"keys_missing_features\"] = X.isnull().sum(axis=1)\n",
    "len(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = [df[\"keys_company_stage\"]]\n",
    "columns = [\"keys_company_stage\", \"confidence_context_broader_company_age_number\", \"confidence_validation_funding_raised_value_total_number\", \"confidence_validation_funding_rounds_number\", \"keys_missing_features\"]\n",
    "colnames = [\"Obs\", \"Age (Years)\", \"Funding Raised (USD, millions)\", \"Funding Rounds (N)\", \"Available Features (N)\"]\n",
    "colfuncs = [{\"N\":len}, \n",
    "    OrderedDict([(\"Median\", np.median),(\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\"))]), \n",
    "    OrderedDict([(\"Median\", lambda x: np.median(x) / 1e6), (\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\") / 1e6)]), \n",
    "    OrderedDict([(\"Median\", np.median),(\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\"))]), \n",
    "    OrderedDict([(\"Median\", lambda x: len(list(df)) - np.median(x)), (\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\") )])]\n",
    "\n",
    "namefunc = OrderedDict(zip(columns, colnames))\n",
    "aggfunc = OrderedDict(zip(columns, colfuncs))\n",
    "\n",
    "order_1 = [\"Pre-Seed\", \"Seed\", \"Series A\", \"Series B\", \"Series C\", \"Series D+\"]\n",
    "\n",
    "tab = df[columns].groupby(groups)\n",
    "tab = tab.agg(aggfunc)\n",
    "tab.rename(columns=namefunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = [df[\"keys_company_stage_group\"]]\n",
    "columns = [\"keys_company_stage\", \"confidence_context_broader_company_age_number\", \"confidence_validation_funding_raised_value_total_number\", \"confidence_validation_funding_rounds_number\", \"keys_missing_features\"]\n",
    "colnames = [\"Obs\", \"Age (Years)\", \"Funding Raised (USD, millions)\", \"Funding Rounds (N)\", \"Available Features (N)\"]\n",
    "colfuncs = [{\"N\":len}, \n",
    "    OrderedDict([(\"Median\", np.median),(\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\"))]), \n",
    "    OrderedDict([(\"Median\", lambda x: np.median(x) / 1e6), (\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\") / 1e6)]), \n",
    "    OrderedDict([(\"Median\", np.median), (\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\"))]),\n",
    "    OrderedDict([(\"Median\", lambda x: len(list(df)) - np.median(x)), (\"IQR\", lambda x: stats.iqr(x,nan_policy=\"omit\") )])]\n",
    "\n",
    "namefunc = OrderedDict(zip(columns, colnames))\n",
    "aggfunc = OrderedDict(zip(columns, colfuncs))\n",
    "\n",
    "tab = df[columns].groupby(groups)\n",
    "tab = tab.agg(aggfunc)\n",
    "tab.rename(columns=namefunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 3. Final test dataset counts grouped by company sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "industries = [x for x in list(df) if x.startswith(\"confidence_context_industry_category_group_list\")]\n",
    "values = [df[industry].value_counts()[1] for industry in industries]\n",
    "values = sorted(values,reverse=True)\n",
    "print(values)\n",
    "names = [\"Software\", \"Internet Services\", \"Media & Entertainment\", \"Commerce\", \"Mobile\", \"Sales & Marketing\", \"Information Technology\", \"Health Care\", \"Hardware\", \"Financial Services\"]\n",
    "sns.barplot(x = values, y = names, order = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SKEW BY FEATURE (GROUPED BY WHETHER ZEROS-REMOVED)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.apply(lambda x: stats.skew(x, nan_policy=\"omit\")).astype(float).plot(kind=\"kde\", label=\"Skew\", xlim=(-20, 40))\n",
    "X.replace(0, np.nan).apply(lambda x: stats.skew(x, nan_policy=\"omit\")).astype(float).plot(kind=\"kde\", label=\"Skew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[KURTOSIS  BY FEATURE (GROUPED BY WHETHER ZEROS-REMOVED)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.apply(lambda x: stats.kurtosis(x, nan_policy=\"omit\")).astype(float).plot(kind=\"kde\", label=\"Skew\", xlim=(-200, 400))\n",
    "X.replace(0, np.nan).apply(lambda x: stats.kurtosis(x, nan_policy=\"omit\")).astype(float).plot(kind=\"kde\", label=\"Skew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BOXPLOT OF FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.apply(lambda x: stats.iqr(x, nan_policy=\"omit\")).astype(float).plot(kind=\"kde\", label=\"IQR\", xlim=(0, 5e8))\n",
    "X.replace(0, np.nan).apply(lambda x: stats.iqr(x, nan_policy=\"omit\")).astype(float).plot(kind=\"kde\", label=\"IQR\", xlim=(0, 5e8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[COVARIANCE MATRIX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(X.corr(), square=True, xticklabels =False, yticklabels=False, vmin=0.5)\n",
    "#pd.DataFrame(np.where(abs(X.corr().stack()) <= 1, True, False)).stack().value_counts()\n",
    "corrs = {thresh/10: pd.DataFrame(np.where(abs(X.corr().stack()) >= thresh/10, True, False)).stack().value_counts(normalize=True)[True] for thresh in range(0, 11)}\n",
    "ax = pd.DataFrame.from_dict(data=corrs, orient=\"index\").plot(kind=\"line\")\n",
    "\n",
    "corrs = {thresh/10: pd.DataFrame(np.where(abs(X.replace(0, np.nan).corr().stack()) >= thresh/10, True, False)).stack().value_counts(normalize=True)[True] for thresh in range(0, 11)}\n",
    "pd.DataFrame.from_dict(data=corrs, orient=\"index\").plot(kind=\"line\",ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(!) Figure 3. Number of missing features per observation (histogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.distplot(df[\"keys_missing_features\"], bins=100, kde=False)\n",
    "g.set(xlim = (0,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(!) Figure 3. Number of missing observations per feature (histogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_by_col =  X.isnull().sum(axis=0)\n",
    "g = sns.distplot(missing_by_col, bins=100, kde=False)\n",
    "g.set(xlim = (0,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3. Mean, median and mode of features (grouped bar plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means_by_col = X.mean(axis=0)#.dropna()\n",
    "means_by_col.plot(kind=\"kde\", label=\"Mean\")\n",
    "\n",
    "medians_by_col = X.median(axis=0)#.dropna()\n",
    "medians_by_col.plot(kind=\"kde\", label=\"Median\")\n",
    "\n",
    "modes_by_col = X.mode(axis=0).T[0]\n",
    "modes_by_col.plot(kind=\"kde\",label=\"Mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3. ROC Curve for different imputations - mean, median, mode (line plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Apply Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "X = X.dropna(axis=1, how = \"all\")\n",
    "imp = Imputer(strategy=\"median\")\n",
    "X_imp = imp.fit_transform(X)\n",
    "X_imp = pd.DataFrame(X_imp, index=X.index, columns=list(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Shift to positive numbers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mins_by_col = X_imp.min(axis=0)#.dropna()\n",
    "mins_by_col.plot(kind=\"kde\", label=\"Minimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pos = X_imp.subtract(X_imp.min(axis=0))\n",
    "X_pos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Start transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "funding = X_pos[\"confidence_validation_funding_raised_value_total_number\"]\n",
    "\n",
    "figure = plt.figure()\n",
    "\n",
    "ax0 = plt.subplot(151)\n",
    "funding.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"Original - No Transformation\") \n",
    "print(\"Skewness (Original): {0:.2f}\".format(stats.skew(funding))) \n",
    "\n",
    "figure.add_subplot(152, sharey=ax0)\n",
    "boxcox = pd.Series(stats.boxcox(funding + 1)[0], index=X_pos.index)\n",
    "boxcox.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"BoxCox Transformation\") \n",
    "print(\"Skewness (BoxCox): {0:.2f}\".format(stats.skew(boxcox))) \n",
    "\n",
    "figure.add_subplot(153, sharey=ax0)\n",
    "log1p = pd.Series(np.log1p(funding), index=X_pos.index)\n",
    "log1p.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"Log1P Transformation\") \n",
    "print(\"Skewness (Log1P): {0:.2f}\".format(stats.skew(log1p)))\n",
    "\n",
    "figure.add_subplot(154, sharey=ax0)\n",
    "sqrt = pd.Series(funding**(1/2), index=X_pos.index)\n",
    "sqrt.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"SQRT Transformation\") \n",
    "print(\"Skewness (SQRT): {0:.2f}\".format(stats.skew(sqrt)))\n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "figure.add_subplot(155, sharey=ax0)\n",
    "binary = pd.Series(np.where(funding == 0, 0, 1), index=X_pos.index)\n",
    "binary.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"Binary Transformation\") \n",
    "print(\"Skewness (Binary): {0:.2f}\".format(stats.skew(binary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Apply transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "ft = FunctionTransformer(np.log1p)\n",
    "X_tf = ft.fit_transform(X_pos)\n",
    "X_tf = pd.DataFrame(X_tf, index=X_pos.index, columns=list(X_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Start scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale\n",
    "\n",
    "funding = X_tf[\"confidence_validation_funding_raised_value_total_number\"]\n",
    "\n",
    "figure = plt.figure()\n",
    "\n",
    "ax0 = plt.subplot(151)\n",
    "funding.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"Original - No Transformation\") \n",
    "print(\"Median: {}, IQR: {}\".format(funding.median(), stats.iqr(funding)))\n",
    "\n",
    "figure.add_subplot(152, sharey=ax0)\n",
    "funding_std = pd.Series(scale(funding), index=X_pos.index)\n",
    "funding_std.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"Standard Scaling\") \n",
    "print(\"Median: {}, IQR: {}\".format(funding_std.median(), stats.iqr(funding_std)))\n",
    "\n",
    "\n",
    "figure.add_subplot(153, sharey=ax0)\n",
    "funding_robust = pd.Series(robust_scale(funding), index=X_pos.index)\n",
    "funding_robust.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"Robust Scaling\") \n",
    "print(\"Median: {}, IQR: {}\".format(funding_robust.median(), stats.iqr(funding_robust)))\n",
    "\n",
    "\n",
    "figure.add_subplot(154, sharey=ax0)\n",
    "funding_mm = pd.Series(minmax_scale(funding), index=X_pos.index)\n",
    "funding_mm.plot(kind=\"hist\", bins=100)\n",
    "plt.title(\"Min Max Scaling\") \n",
    "print(\"Median: {}, IQR: {}\".format(funding_mm.median(), stats.iqr(funding_mm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Apply scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X_std = scale(X_tf)\n",
    "X_std = pd.DataFrame(X_std, index=X_tf.index, columns=list(X_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Principal Components Analysis (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def screeplot(pca, X):\n",
    "    y = pca.explained_variance_\n",
    "    x = np.arange(len(y)) + 1\n",
    "    plt.plot(x, y)\n",
    "    plt.ylabel(\"Eigenvalue\")\n",
    "    plt.xlabel(\"Component Number\")\n",
    "    plt.xlim(1,None)\n",
    "    return y\n",
    "\n",
    "pca = PCA().fit(X_std)\n",
    "eigenvalues = screeplot(pca,X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "features = list(X_std)\n",
    "f_map = {x: '_'.join(x.split(\"_\")[:3]) for x in features}\n",
    "f_group = defaultdict(list)\n",
    "for f,g in f_map.items():\n",
    "    f_group[g].append(f)\n",
    "agg_group = {}\n",
    "for g,l in f_group.items():\n",
    "    combo = combinations(l, 2)\n",
    "    for x,y in combo:\n",
    "        corr = stats.spearmanr(X_std[x][:100], X_std[y][:100])[0]\n",
    "        if corr < 0: X_std[y] *= -1\n",
    "    tot = X_std[l].sum(axis=1)\n",
    "    agg_group[g] = tot\n",
    "X_grp = pd.DataFrame(agg_group)\n",
    "grp_corr = X_grp.corr(method=\"spearman\")\n",
    "mask = np.zeros_like(grp_corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f_names = [x.split(\"_\")[2] for x in list(X_grp)]\n",
    "ax = sns.heatmap(grp_corr,square=True, mask=mask, xticklabels=f_names, yticklabels=f_names)\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_grp)\n",
    "eigenvalues = screeplot(pca,X_grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.2 Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.3 Predictive Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Table 3.5 Comparison of 2013 slice from 2016 dataset with original 2013 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
